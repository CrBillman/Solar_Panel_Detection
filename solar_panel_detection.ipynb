{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Questions: how do input image - flatten or include rows and columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Autoreload imports of modified .py modules\n",
    "import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# NN Modules\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# OpenCV\n",
    "import cv2\n",
    "\n",
    "# UNET module\n",
    "import solar_panel_detection.unet as unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    '''\n",
    "    Resize the image to a fixed size, then flatten the image into\n",
    "    1D list of raw pixel intensities.\n",
    "    Note: resizing will lose information about image\n",
    "    Note: can choose different interpolation schemes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: image-like\n",
    "        input image\n",
    "    size: tuple\n",
    "        resolution of output vector\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    resized image\n",
    "    '''\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in example photo\n",
    "imTrain = cv2.imread('data/3385828/11ska460890.tif')\n",
    "\n",
    "# Load dummy target image as grayscale\n",
    "imTarget = cv2.imread('data/11ska460890_dummy.tif', 0)\n",
    "# Replace all non-black pixel RGB (0, 0, 0) with 255 (white) for target\n",
    "imTarget[imTarget>0] = 255\n",
    "imTarget[imTarget==0] = 1\n",
    "imTarget[imTarget==255] = 0\n",
    "imTarget = imTarget*255\n",
    "\n",
    "# Load dummy image again and make binary target for training\n",
    "target = cv2.imread('data/11ska460890_dummy.tif', 0)\n",
    "target[target>0] = 255\n",
    "target[target==0] = 1\n",
    "target[target==255] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resize images\n",
    "resize = (128, 128)\n",
    "imTrain = cv2.resize(imTrain, resize)  \n",
    "imTarget = cv2.resize(imTarget, resize)  \n",
    "target = cv2.resize(target, resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View images\n",
    "cv2.imshow('image', imTarget)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize and scale training data\n",
    "training = imTrain.astype('float32')\n",
    "trainMean = np.mean(training)\n",
    "trainStd = np.std(training)\n",
    "training -= trainMean\n",
    "training /= trainStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert target to categorical variables for cross-entropy metric\n",
    "nClasses = 2\n",
    "target = to_categorical(target, num_classes=nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape training and target data with n_images\n",
    "nImages = 1\n",
    "training = training.reshape(nImages,resize[0],resize[1],3)\n",
    "target = target.reshape(nImages,resize[0],resize[1],nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create UNET object and create model\n",
    "UNET = unet.Unet(resize[0], resize[1], 3)\n",
    "modelUnet = UNET.create_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " - 4s - loss: 0.7245 - categorical_accuracy: 0.0103\n",
      "Epoch 2/3\n",
      " - 2s - loss: 0.5968 - categorical_accuracy: 0.9998\n",
      "Epoch 3/3\n",
      " - 2s - loss: 0.0427 - categorical_accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1973891d4e0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "modelUnet.fit(x=training, y=target, epochs=3, batch_size=None, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get predictions and output image of predictions\n",
    "predictions = modelUnet.predict(x=training, batch_size=None)\n",
    "predictions[predictions>0] = 255\n",
    "predImage = np.argmax(predictions[0], axis=2)\n",
    "cv2.imwrite('predImage.jpg', predImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'waitkey'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-0f5e7e433f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Prediction'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredImage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'waitkey'"
     ]
    }
   ],
   "source": [
    "cv2.imshow('Prediction', predImage)\n",
    "cv2.waitkey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tf-keras",
   "language": "python",
   "name": "tf-keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
